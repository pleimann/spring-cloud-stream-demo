version: '3.9'

volumes:
  kafka-data:

networks:
  kafka-cluster:
    driver: bridge

services:
  broker:
    image: confluentinc/cp-kafka:7.0.0
    hostname: broker
    container_name: broker
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9101:9101"
    networks:
      - kafka-cluster
    volumes:
      - kafka-data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: "EXTERNAL://localhost:9092,CONTROLLER://broker:29093,INTERNAL://broker:29092"
      KAFKA_ADVERTISED_LISTENERS: "EXTERNAL://localhost:9092,INTERNAL://broker:29092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    command:
      - bash
      - -c
      - |
        # Docker workaround: Remove check for KAFKA_ZOOKEEPER_CONNECT parameter
        sed -i '/KAFKA_ZOOKEEPER_CONNECT/d' /etc/confluent/docker/configure

        # Docker workaround: Ignore cub zk-ready
        sed -i 's/cub zk-ready/echo ignore zk-ready/' /etc/confluent/docker/ensure

        # KRaft required step: Format the storage directory with a new cluster ID
        echo "kafka-storage format --ignore-formatted -t `kafka-storage random-uuid` -c /etc/kafka/kafka.properties" >> /etc/confluent/docker/ensure

        /etc/confluent/docker/run

  ui:
    build:
      dockerfile: ../kafdrop.Dockerfile
    restart: "no"
    hostname: kafdrop
    container_name: kafdrop
    ports:
      - "9000:9000"
    environment:
      WAIT_HOSTS: "broker:29092"
      WAIT_BEFORE: 30
      WAIT_SLEEP_INTERVAL: 2
      KAFKA_BROKERCONNECT: "broker:29092"
    depends_on:
      - "broker"

  schema-registry:
    image: confluentinc/cp-schema-registry:7.0.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    networks:
      - kafka-cluster
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  ksql-server:
    image: confluentinc/cp-ksql-server:latest
    hostname: ksql-server
    container_name: ksql-server
    profiles:
      - kafka-ksql
      - kafka-all
    depends_on:
      - kafka
      - schema-registry
    ports:
      - '31003:31003'
      - '8088:8088'
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_SERVICE_ID: asgard
      KSQL_JMX_HOSTNAME: "localhost"
      KSQL_JMX_PORT: 31003
      KSQL_LOG4J_ROOT_LOGLEVEL: "INFO"
      KSQL_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      # --- Processing log config ---
      KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: kafka:29092
      KSQL_LOG4J_PROCESSING_LOG_TOPIC: asgard_processing_log
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: asgard_processing_log
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"

  ksql-cli:
    image: confluentinc/cp-ksql-cli:latest
    hostname: ksql-cli
    container_name: ksql-cli
    profiles:
      - kafka-ksql
      - kafka-all
    depends_on:
      - ksql-server
    entrypoint: /bin/sh
    tty: true

  connect:
    image: cnfldemos/kafka-connect-datagen:0.5.0-6.2.0
    hostname: connect
    container_name: connect
    profiles:
      - kafka-connect
      - kafka-all
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8083:8083"
    networks:
      - kafka-cluster
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR

  rest-proxy:
    image: confluentinc/cp-kafka-rest:7.0.0
    hostname: rest-proxy
    container_name: rest-proxy
    profiles:
      - kafka-rest
      - kafka-all
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8082:8082"
    networks:
      - kafka-cluster
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'